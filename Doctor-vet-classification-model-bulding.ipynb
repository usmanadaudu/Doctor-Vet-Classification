{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016b870f",
   "metadata": {},
   "source": [
    "# Doctor and Veterinary Classification using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc00ba50",
   "metadata": {},
   "source": [
    "This notebook is for building a model which will correctly classify a number of given reddit users as practicing doctors, practicng veterinary or others based on each user's comments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c521b2af",
   "metadata": {},
   "source": [
    "The dataset for this task would be sourced from a databased whose link is given as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054f1c7",
   "metadata": {},
   "source": [
    "[postgresql://niphemi.oyewole:W7bHIgaN1ejh@ep-delicate-river-a5cq94ee-pooler.us-east-2.aws.neon.tech/Vetassist?statusColor=F8F8F8&env=&name=redditors%20db&tLSMode=0&usePrivateKey=false&safeModeLevel=0&advancedSafeModeLevel=0&driverVersion=0&lazyload=false](postgresql://niphemi.oyewole:W7bHIgaN1ejh@ep-delicate-river-a5cq94ee-pooler.us-east-2.aws.neon.tech/Vetassist?statusColor=F8F8F8&env=&name=redditors%20db&tLSMode=0&usePrivateKey=false&safeModeLevel=0&advancedSafeModeLevel=0&driverVersion=0&lazyload=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add21a4a",
   "metadata": {},
   "source": [
    "However, trying to access the database with the given link would result in errors\n",
    "\n",
    "Therefore, a modified version of the link would be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cafbbe",
   "metadata": {},
   "source": [
    "## Module Importations and Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251773f6",
   "metadata": {},
   "source": [
    "Before continuing, needed libraries would be imported below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b2600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re             # for regrex operations\n",
    "import string         # for removing punctuations\n",
    "import numpy as np    # for mathematical calculations\n",
    "import pandas as pd    # for working with structured data (dataframes)\n",
    "from sqlalchemy import create_engine # for connecting to database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239f106",
   "metadata": {},
   "source": [
    "The modified link to access the database is defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d0e2e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the connection link\n",
    "conn_str = \"postgresql://niphemi.oyewole:endpoint=ep-delicate-river-a5cq94ee-pooler;W7bHIgaN1ejh@ep-delicate-river-a5cq94ee-pooler.us-east-2.aws.neon.tech/Vetassist?sslmode=require\"\n",
    "\n",
    "# create connection to the databse\n",
    "engine =  create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b8994",
   "metadata": {},
   "source": [
    "First, lets take a look at the tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f500abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sql query for retrieving the tables in the database\n",
    "sql_for_tables = \"\"\"\n",
    "SELECT\n",
    "    table_schema || '.' || table_name\n",
    "FROM\n",
    "    information_schema.tables\n",
    "WHERE\n",
    "    table_type = 'BASE TABLE'\n",
    "AND\n",
    "    table_schema NOT IN ('pg_catalog', 'information_schema');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ec36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the tables in a dataframe\n",
    "tables_df = pd.read_sql_query(sql_for_tables, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1553cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public.reddit_usernames_comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public.reddit_usernames</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ?column?\n",
       "0  public.reddit_usernames_comments\n",
       "1           public.reddit_usernames"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f12059",
   "metadata": {},
   "source": [
    "There are two tables in the database as shown above\n",
    "\n",
    "Each table would be saved in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101d9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_for_table1 = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    public.reddit_usernames_comments;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2053d7d",
   "metadata": {},
   "source": [
    "> Note: The code below may take a while to run. If it fails, reconnect the engine above then rerun the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e66c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comment_df = pd.read_sql_query(sql_for_table1, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_for_table2 = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    public.reddit_usernames;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb403fa",
   "metadata": {},
   "source": [
    "> Note: The code below may take a while to run. If it fails, reconnect the engine above then rerun the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6a2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_df = pd.read_sql_query(sql_for_table2, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18c1cd",
   "metadata": {},
   "source": [
    "Lets take a look at the tables one after the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ab901d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoveAGoodTwist</td>\n",
       "      <td>Female, Kentucky.  4 years out. Work equine on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wahznooski</td>\n",
       "      <td>As a woman of reproductive age, fuck Texas|As ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churro_The_fish_Girl</td>\n",
       "      <td>what makes you want to become a vet?|what make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abarthch</td>\n",
       "      <td>I see of course there are changing variables, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VoodooKing</td>\n",
       "      <td>I have 412+ and faced issues because wireguard...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                           comments\n",
       "0        LoveAGoodTwist  Female, Kentucky.  4 years out. Work equine on...\n",
       "1            wahznooski  As a woman of reproductive age, fuck Texas|As ...\n",
       "2  Churro_The_fish_Girl  what makes you want to become a vet?|what make...\n",
       "3              abarthch  I see of course there are changing variables, ...\n",
       "4            VoodooKing  I have 412+ and faced issues because wireguard..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_comment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38459979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3276, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_comment_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea0189",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f98da6",
   "metadata": {},
   "source": [
    "This table (now dataframe) contains usernames of users and their comments\n",
    "\n",
    "Lets look at a comment in order to understand how it is structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8102b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all comments for first user\n",
    "user_comment_df[\"comments\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c36492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split comments into individual comments\n",
    "first_comments = user_comment_df[\"comments\"][0].split(\"|\")\n",
    "\n",
    "# get the number of comments for first user\n",
    "len(first_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc971bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove repeated comments\n",
    "unique_comment = []\n",
    "for comment in first_comments:\n",
    "    if comment in unique_comment:\n",
    "        continue\n",
    "    else:\n",
    "        unique_comment.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04afe6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unique comments for first user: 1\n",
      "\n",
      "['Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of unique comments for first user: {len(unique_comment)}\")\n",
    "print()\n",
    "print(unique_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7b745",
   "metadata": {},
   "source": [
    "It can be seen that the comment column contains multiple comments separated with \"|\"\n",
    "\n",
    "It can also be seen that there are repeated comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c10140",
   "metadata": {},
   "source": [
    "Lets check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683d8e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username    0\n",
       "comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_comment_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33874145",
   "metadata": {},
   "source": [
    "There are no missig values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20aa3b4",
   "metadata": {},
   "source": [
    "Let's check if there are duplicate usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a98e504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicated usernames\n"
     ]
    }
   ],
   "source": [
    "if user_comment_df[\"username\"].nunique() == user_comment_df.shape[0]:\n",
    "    print(\"There are no duplicated usernames\")\n",
    "else:\n",
    "    print(\"There are duplicated usernames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc82d086",
   "metadata": {},
   "source": [
    "Lets explore the second dataframe also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b99854ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>isused</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoveAGoodTwist</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drawntage</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinkPast84</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heatthequestforfire</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most-Exit-5507</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              username  isused   subreddit  created_at\n",
       "0       LoveAGoodTwist    True  Veterinary  2024-05-02\n",
       "1            drawntage    True  Veterinary  2024-05-02\n",
       "2           LinkPast84    True  Veterinary  2024-05-02\n",
       "3  heatthequestforfire    True  Veterinary  2024-05-02\n",
       "4       Most-Exit-5507    True  Veterinary  2024-05-02"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4ad065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8259 entries, 0 to 8258\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   username    8259 non-null   object\n",
      " 1   isused      8259 non-null   bool  \n",
      " 2   subreddit   8259 non-null   object\n",
      " 3   created_at  8259 non-null   object\n",
      "dtypes: bool(1), object(3)\n",
      "memory usage: 201.8+ KB\n"
     ]
    }
   ],
   "source": [
    "user_info_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67059c4b",
   "metadata": {},
   "source": [
    "From the summary above, we se that there are no missing values as each feature has exactly 8259 values which is total entries in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50c809",
   "metadata": {},
   "source": [
    "Let's check if there are duplicate usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c34621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicated usernames\n"
     ]
    }
   ],
   "source": [
    "if user_info_df[\"username\"].nunique() == user_info_df.shape[0]:\n",
    "    print(\"There are no duplicated usernames\")\n",
    "else:\n",
    "    print(\"There are duplicated usernames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49e2fa",
   "metadata": {},
   "source": [
    "At this point lets create a function to preprocess the comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374fb04",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7a0925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_web_link(text):\n",
    "    text_list = text.split(\"|\")\n",
    "    for i in range(len(text_list)):\n",
    "        text_list[i] = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "                              \"\", text_list[i].strip())\n",
    "    return \" | \".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f485fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_directories(text):\n",
    "    text_list = text.split(\"|\")\n",
    "    for i in range(len(text_list)):\n",
    "        text_list[i] = re.sub(r\"(/[a-zA-Z0-9_]+)+(/)*(.[a-zA-Z_]+)*\",\n",
    "                              \"\", text_list[i]).strip()\n",
    "    return \" | \".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0755af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    text_list = text.split(\"|\")\n",
    "    for i in range(len(text_list)):\n",
    "        text_list[i] = ''.join([l for l in text_list[i] if l not in string.punctuation])\n",
    "    return \" | \".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36574de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphabets(text):\n",
    "    text_list = text.split(\"|\")\n",
    "    for i in range(len(text_list)):\n",
    "        text_list[i] = re.sub(r\"[^a-zA-Z ]\", \"\", text_list[i].strip())\n",
    "    return \" | \".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45cfddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unneeded_spaces(text):\n",
    "    text_list = text.split(\"|\")\n",
    "    for i in range(len(text_list)):\n",
    "        text_list[i] = re.sub(r\"(\\s)+\", \" \", text_list[i].strip())\n",
    "    return \" | \".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc9dd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_sentence(text):\n",
    "    text_list = text.split(\"|\")\n",
    "    unique_comment = []\n",
    "    for comment in text_list:\n",
    "        if comment.strip() in unique_comment:\n",
    "            continue\n",
    "        else:\n",
    "            unique_comment.append(comment.strip())\n",
    "    return \" | \".join(unique_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff34a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_preprocessing(text):\n",
    "    text = remove_web_link(text)\n",
    "    text = remove_directories(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_non_alphabets(text)\n",
    "    text = remove_unneeded_spaces(text)\n",
    "    text = remove_repeated_sentence(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1690c6",
   "metadata": {},
   "source": [
    "## Hand Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6495d1ef",
   "metadata": {},
   "source": [
    "Lets check out the unique values in the subreddit feature as well as the count of each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "161b5858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "Veterinary          6170\n",
       "MysteriumNetwork     967\n",
       "medicine             409\n",
       "HeliumNetwork        400\n",
       "orchid               303\n",
       "vet                   10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_count = user_info_df['subreddit'].value_counts()\n",
    "subreddit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb7feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = list(subreddit_count.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f66d6d",
   "metadata": {},
   "source": [
    "Lets explore each of this subreddit categories starting from the least (the bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "684e8a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vet Subreddit Count\n",
      "Table1: 10\n",
      "Table2: 9\n"
     ]
    }
   ],
   "source": [
    "# get the number of vet subscribers that are in the first dataset\n",
    "\n",
    "# initialize counter\n",
    "user_count = 0\n",
    "# create container for vet subcribers also in the first dataframe\n",
    "vet_subscribers = []\n",
    "\n",
    "# for each username who is a subcriber of vet\n",
    "for user in user_info_df[user_info_df['subreddit'] == \"vet\"][\"username\"]:\n",
    "    # if username is found in table1\n",
    "    if not user_comment_df[user_comment_df[\"username\"] == user].empty:\n",
    "        # increment counter by 1\n",
    "        user_count += 1\n",
    "        # capture the username\n",
    "        vet_subscribers.append(user)\n",
    "\n",
    "print(\"Vet Subreddit Count\")\n",
    "print(\"Table1: {}\".format(subreddit_count[\"vet\"]))\n",
    "print(f\"Table2: {user_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382844a",
   "metadata": {},
   "source": [
    "One of the suncribers of vet is not in the first dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164815f2",
   "metadata": {},
   "source": [
    "At this point it would be better to combine both dataset into one\n",
    "\n",
    "Lets do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ed2b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_user_df = pd.merge(user_comment_df, user_info_df,\n",
    "                          on=\"username\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bec6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>comments</th>\n",
       "      <th>isused</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoveAGoodTwist</td>\n",
       "      <td>Female, Kentucky.  4 years out. Work equine on...</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wahznooski</td>\n",
       "      <td>As a woman of reproductive age, fuck Texas|As ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churro_The_fish_Girl</td>\n",
       "      <td>what makes you want to become a vet?|what make...</td>\n",
       "      <td>True</td>\n",
       "      <td>Veterinary</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abarthch</td>\n",
       "      <td>I see of course there are changing variables, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>MysteriumNetwork</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VoodooKing</td>\n",
       "      <td>I have 412+ and faced issues because wireguard...</td>\n",
       "      <td>False</td>\n",
       "      <td>MysteriumNetwork</td>\n",
       "      <td>2024-05-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                           comments  \\\n",
       "0        LoveAGoodTwist  Female, Kentucky.  4 years out. Work equine on...   \n",
       "1            wahznooski  As a woman of reproductive age, fuck Texas|As ...   \n",
       "2  Churro_The_fish_Girl  what makes you want to become a vet?|what make...   \n",
       "3              abarthch  I see of course there are changing variables, ...   \n",
       "4            VoodooKing  I have 412+ and faced issues because wireguard...   \n",
       "\n",
       "   isused         subreddit  created_at  \n",
       "0    True        Veterinary  2024-05-02  \n",
       "1    True        Veterinary  2024-05-02  \n",
       "2    True        Veterinary  2024-05-02  \n",
       "3    True  MysteriumNetwork  2024-05-02  \n",
       "4   False  MysteriumNetwork  2024-05-03  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1917cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   username    3276 non-null   object\n",
      " 1   comments    3276 non-null   object\n",
      " 2   isused      3276 non-null   bool  \n",
      " 3   subreddit   3276 non-null   object\n",
      " 4   created_at  3276 non-null   object\n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 105.7+ KB\n"
     ]
    }
   ],
   "source": [
    "reddit_user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c104f6",
   "metadata": {},
   "source": [
    "Now let us continue with the subreddits\n",
    "\n",
    "Starting from the bottom and moving up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "848d4827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Veterinary',\n",
       " 'MysteriumNetwork',\n",
       " 'medicine',\n",
       " 'HeliumNetwork',\n",
       " 'orchid',\n",
       " 'vet']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd5ff9",
   "metadata": {},
   "source": [
    "Let's check out the comments of the vet subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7296f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of vet subscribers\n",
    "vet_sub_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"vet\"][\"username\"].values\n",
    "\n",
    "# get the comments made by vet subscribers\n",
    "vet_sub_comments = reddit_user_df[reddit_user_df[\"subreddit\"] == \"vet\"][\"comments\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e2729e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_vet2: The puppy was brought in for its first round of vaccinations.\n",
      "test_vet3: The adult horse was treated for laminitis.\n",
      "test_vet4: The juvenile bird was treated for a wing injury.\n",
      "test_vet5: The senior cat was brought in for a routine health check-up.\n",
      "test_vet6: I just performed a neutering procedure on a cat.\n",
      "test_vet7: The dog’s condition is improving after the deworming treatment.\n",
      "test_vet8: The X-ray showed a fracture in the bird’s wing.\n",
      "test_vet9: I prescribed flea prevention medication for the puppy.\n",
      "test_vet: The horse’s blood test revealed signs of equine infectious anemia.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vet_sub_list)):\n",
    "    print(f\"{vet_sub_list[i]}: {vet_sub_comments[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8dcdd",
   "metadata": {},
   "source": [
    "It would be logical for a practicing veterinarian or anyone whose work is related to veterinary to follow \"vet\" subreddit. This shows closeness to veterinary but does not guarantee being a veterinarian\n",
    "\n",
    "It can be seen that all these people have just one comment each\n",
    "\n",
    "Many spoke in 3rd person form which is hard to say if they are doctors or not\n",
    "\n",
    "Only test_vet6 and test_vet9 can be confirmed to be practicing veterinarian\n",
    "Others can be classified in the others category since there must be a solid evidence in order to classifier a user as a practicing veterinarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98bb3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store usernames of confirmed veterinarians\n",
    "veterinarians = [\"test_vet6\", \"test_vet9\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62485208",
   "metadata": {},
   "source": [
    "> It is noteworthy that this type of problem is usually solved effectively with labelled dataset\n",
    "\n",
    "> However with unlabelled data as the one here, hand engineering may be employed to some extent enough to build a model, therafter the model can predict the rest\n",
    "\n",
    "> That is the approach I wish to employ for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15769ef6",
   "metadata": {},
   "source": [
    "Now, unto next subreddit (orchid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a60e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of orchid subscribers\n",
    "orchid_sub_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"orchid\"][\"username\"].values\n",
    "\n",
    "# get the comments made by orchid subscribers\n",
    "orchid_sub_comment_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"orchid\"][\"comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb36473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchid sunscrbers: ['Think_Not_Doer' 'Personal-Escape4283' 'timee_bot' 'erlingspaulsen']\n",
      "Number of orchid subscribers: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orchid sunscrbers: {orchid_sub_list}\")\n",
    "print(f\"Number of orchid subscribers: {len(orchid_sub_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbcb637",
   "metadata": {},
   "source": [
    "It would be neccesary to preprocess our data first as the comments of users who subscribe to orchid is a bit much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d150433",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchid_sub_comment_list = orchid_sub_comment_list.apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54c8806b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([205, 241, 306, 1547], dtype='int64')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchid_sub_comment_list.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc95362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice If anyone is hosting a Mysterium node and have a spare hard disk its very easy to run a Storj node alongside Mysterium I do this on my Raspberry Pi | My Raspberry Pi is running the Mysterium Rasbian image Then I just followed the Storj installation guide and installed Docker engine downloaded their Docker image and started the Storj storage node inside its own container I just looked up Presearch and it looks like you can run their node through a Docker container so this should be okay to do alongside Mysterium To install the Docker engine on Rasbian you can follow this guideinstallusingtheconveniencescriptThanks for bringing it up as I was not aware of this project Might as well try this myself | Doesnt look like Presearch node is supported on Raspberry Pi yet Hardware Specification Docker image is only for x x based CPUs for now We plan to support ARM Raspberry Pi in the future but were currently focused on fixing bugs and making sure the current platform is robust before additional supported platforms | Thats not an issue Im in the same boat as you started out with the Mystberry image from Mysterium then I installed the Docker engine on top of that So Storj is just running inside its own Docker container kind of like a virtual machine inside the Raspberry PI while the myst service and OpenVPN is running outside Docker on the Mystberry OS itself It has been running a couple of months now without any issuesIm also trying to install an NKN node on the Raspberry PI now not using a Docker image but on the OS itself Trying to get the most out of that little thing haha | Correct SSH into your Raspberry Pi as the myst user and then switch to root user with sudo su You can then install the Docker engine as root | Havent really found any other projects where I can run a node on Raspberry Pi yetBy running Myst Storj and NKN my Pi is using around CPU and memory with a CPU C Seems like NKN is using most resources out of the three'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchid_sub_comment_list[1547]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c0c23",
   "metadata": {},
   "source": [
    "Checking the comments of all the 4 people who subscribed to orchid shows none of them is either a practicing doctor or a practicing veterinarian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc959616",
   "metadata": {},
   "source": [
    "Next subreddit is HeliumNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "367e8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of orchid subscribers\n",
    "HeliumNetwork_sub_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"HeliumNetwork\"][\"username\"].values\n",
    "\n",
    "# get the comments made by orchid subscribers\n",
    "HeliumNetwork_sub_comment_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"HeliumNetwork\"][\"comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbd783c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeliumNetwork sunscrbers: ['Best_Bid_9327' 'SoulReaver-SS' 'Imthefatboyb' 'Passi-RVN' 'alexiskef'\n",
      " 'drunknfoo']\n",
      "Number of HeliumNetwork subscribers: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"HeliumNetwork sunscrbers: {HeliumNetwork_sub_list}\")\n",
    "print(f\"Number of HeliumNetwork subscribers: {len(HeliumNetwork_sub_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fbe0ac",
   "metadata": {},
   "source": [
    "Thereare 6 sunscribers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b8c04",
   "metadata": {},
   "source": [
    "Lets proprocess the data of all users who subscribe to HeliumNetwork in order to view it properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f30ac791",
   "metadata": {},
   "outputs": [],
   "source": [
    "HeliumNetwork_sub_comment_list = HeliumNetwork_sub_comment_list.apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7233755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([93, 442, 458, 632, 670, 1504], dtype='int64')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HeliumNetwork_sub_comment_list.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a931ae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was averaging and MYST After three days of mainnet total about MYST and the other node nothing Not worth bothering for me anymore until something changes'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HeliumNetwork_sub_comment_list[1504]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f847c10a",
   "metadata": {},
   "source": [
    "Everone who subscribes to HeliumNetwork belongs to the others category (None of them is perceved to be a practicing doctor or veterinarian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a65a4b",
   "metadata": {},
   "source": [
    "Lets take alook at the medicine subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b3a4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of orchid subscribers\n",
    "medicine_sub_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"medicine\"][\"username\"].values\n",
    "\n",
    "# get the comments made by orchid subscribers\n",
    "medicine_sub_comment_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"medicine\"][\"comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "289c60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medicine subscrbers: ['test_doctor2' 'test_doctor3' 'test_doctor4' 'test_doctor5'\n",
      " 'test_doctor6' 'test_doctor7' 'test_doctor8' 'test_doctor1']\n",
      "Number of medicine subscribers: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"medicine subscrbers: {medicine_sub_list}\")\n",
    "print(f\"Number of medicine subscribers: {len(medicine_sub_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478da1e4",
   "metadata": {},
   "source": [
    "Thereare 8 sunscribers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e9c932",
   "metadata": {},
   "source": [
    "Lets proprocess the data of all users who subscribe to medicine in order to view it properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1eb5113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_sub_comment_list = medicine_sub_comment_list.apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dde1d69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_doctor2: The elderly man is recovering from hip replacement surgery\n",
      "test_doctor3: The teenage boy was treated for a sports injury\n",
      "test_doctor4: The woman is expecting a baby and visited for a prenatal checkup\n",
      "test_doctor5: I just performed an appendectomy on a patient\n",
      "test_doctor6: The patients blood pressure is stabilizing after the medication\n",
      "test_doctor7: The MRI scan revealed a tumor in the patients brain\n",
      "test_doctor8: I prescribed antibiotics for the patients bacterial infection\n",
      "test_doctor1: The patients EKG showed signs of a possible heart attack\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(medicine_sub_list)):\n",
    "    print(f\"{medicine_sub_list[i]}: {medicine_sub_comment_list.values[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431dd6b2",
   "metadata": {},
   "source": [
    "Just like the vet subreddit, most of the users in this category speak in third person form which makes it hard to say if they are really practicing doctor or a medical practitioner like nurse student etc\n",
    "\n",
    "Only test_doctor5 and tes_doctor8 are confirmed to be practicing doctors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a867a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_doctor5', 'test_doctor8']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doctors = [\"test_doctor5\", \"test_doctor8\"]\n",
    "Doctors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a418a4",
   "metadata": {},
   "source": [
    "Lets take alook at the next subreddit, MysteriumNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b17d26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of MysteriumNetwork subscribers\n",
    "MysteriumNetwork_sub_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"MysteriumNetwork\"][\"username\"].values\n",
    "\n",
    "# get the comments made by MysteriumNetwork subscribers\n",
    "MysteriumNetwork_sub_comment_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"MysteriumNetwork\"][\"comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1d8b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MysteriumNetwork subscribers: 967\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of MysteriumNetwork subscribers: {len(MysteriumNetwork_sub_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ba3ba",
   "metadata": {},
   "source": [
    "There are quite a lot of users who subscribe to MysteriumNetwork\n",
    "\n",
    "Nevertheless we still need to preprocess the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "034db18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MysteriumNetwork_sub_comment_list = MysteriumNetwork_sub_comment_list.apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e56083",
   "metadata": {},
   "source": [
    "Lets take alook at the last subreddit also, Veterinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27307c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of Veterinary subscribers\n",
    "Veterinary_sub_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"Veterinary\"][\"username\"].values\n",
    "\n",
    "# get the comments made by Veterinary subscribers\n",
    "Veterinary_sub_comment_list = reddit_user_df[reddit_user_df[\"subreddit\"] == \"Veterinary\"][\"comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fdb9730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Veterinary subscribers: 2282\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Veterinary subscribers: {len(Veterinary_sub_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bbf4e",
   "metadata": {},
   "source": [
    "There are quite a lot of users who subscribe to Veterinary also\n",
    "\n",
    "Lets first preprocess the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ba01f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Veterinary_sub_comment_list = Veterinary_sub_comment_list.apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0ad5a",
   "metadata": {},
   "source": [
    "At this point is would be better to build the model on the 4 subreddit we have checked so far then predict the category for the remianing users who subscribe to the remaining 2 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646aef71",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214486ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e101886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef7218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47619ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd87de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f39820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197b221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a2db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
